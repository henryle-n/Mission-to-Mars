{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymongo as pmo\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "from splinter import Browser\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Web Browser Driver for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path of browser driver want to use\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "\n",
    "# specify the name of browser want to use\n",
    "browser_name = 'chrome'\n",
    "\n",
    "# specify parser used\n",
    "lib_used = 'html.parser'\n",
    "\n",
    "# start browser\n",
    "browser = Browser(browser_name, **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to NASA Mars news\n",
    "article_url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# access & get content \n",
    "browser.visit(article_url)\n",
    "\n",
    "t_wait = 0\n",
    "del_t = 0.25\n",
    "\n",
    "# condition to make sure the webpage is loaded\n",
    "if browser.is_element_present_by_tag('/html') == False:\n",
    "    time.sleep(t_wait)\n",
    "    t_wait += del_t\n",
    "else:\n",
    "    pass\n",
    "\n",
    "soup = bsp(browser.html, lib_used)\n",
    "\n",
    "# return results\n",
    "results = soup.find_all('div', class_='list_text')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the lastest news from the list with index = 0 :: indication of the top latest\n",
    "latest_news = results[0]\n",
    "latest_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow: \n",
    "    # find all the div, then use the unique class of each div  \n",
    "    # to access the content of a specific div\n",
    "for tag in latest_news.find_all('div'):\n",
    "    if \"content_title\" in tag.attrs[\"class\"]:\n",
    "        las_news_title = tag.a.text\n",
    "        las_news_link = f\"https://mars.nasa.gov/{tag.a['href']}\"\n",
    "    elif \"article_teaser_body\" in tag.attrs[\"class\"]:\n",
    "        las_news_content = tag.text\n",
    "     \n",
    "        \n",
    "# print out what found in the loop\n",
    "print(f'>> Lastest news of Mars from NASA:\\n\\\n",
    "    {las_news_title}\\n\\n\\\n",
    ">> News Content:\\n\\\n",
    "    {las_news_content}\\n\\n\\\n",
    ">> News Link:\\n\\\n",
    "    {las_news_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to Mars Image\n",
    "ft_img_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# access website\n",
    "browser.visit(ft_img_url)\n",
    "\n",
    "t_wait = 0\n",
    "del_t = 0.25\n",
    "\n",
    "# condition to make sure the webpage is loaded\n",
    "if browser.is_element_present_by_tag('/html') == False:\n",
    "    time.sleep(t_wait)\n",
    "    t_wait += del_t\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "# click on couple of buttons to gain access to the full size image page\n",
    "# condition with if to make sure the subsequent codes will still run incase of issue\n",
    "if browser.links.find_by_partial_text('FULL IMAGE'):\n",
    "    browser.links.find_by_partial_text('FULL IMAGE').click()\n",
    "    \n",
    "else:\n",
    "    print(f'No \"FULL IMAGE\" Button found')\n",
    "  \n",
    "    \n",
    "if browser.links.find_by_partial_text('more info'):\n",
    "    browser.links.find_by_partial_text('more info').click()\n",
    "    \n",
    "    # delay time so browser can load before proceeding\n",
    "    time.sleep(2)\n",
    "    \n",
    "else:\n",
    "     print(f'No \"more info\" Button found')\n",
    "        \n",
    "# condition with if to make sure the subsequent codes will still run incase of issue\n",
    "if browser.links.find_by_partial_href('largesize'):\n",
    "    browser.links.find_by_partial_href('largesize').click()\n",
    "    \n",
    "else:\n",
    "    print(f'No \"Full size Image \" Button found')\n",
    "    \n",
    "feature_image_url = browser.url\n",
    "feature_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# link to Mars weather\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# access & get content \n",
    "browser.visit(weather_url)\n",
    "\n",
    "t_wait = 0\n",
    "del_t = 0.25\n",
    "\n",
    "# condition to make sure the webpage is loaded\n",
    "if browser.is_element_present_by_tag('/html') == False:\n",
    "    time.sleep(t_wait)\n",
    "    t_wait += del_t\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# create soup object\n",
    "soup = bsp(browser.html, lib_used)\n",
    "print(soup)\n",
    "\n",
    "# return results\n",
    "results = soup.find_all('span', class_='css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop thru the list and find partial match for the weather content\n",
    "# as soon as the first string read, stop the loop\n",
    "for ea_tag in results:\n",
    "    if ea_tag.text[0:7] == \"InSight\":\n",
    "        mars_weather = ea_tag.text\n",
    "        break\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to Mars weather\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# access & get content \n",
    "browser.visit(facts_url)\n",
    "time.sleep(3)   \n",
    "# soup = bsp(browser.html, lib_used)\n",
    "\n",
    "\n",
    "\n",
    "# return results\n",
    "# results = soup.find_all('span', class_='css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0')\n",
    "# results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(facts_url)\n",
    "tables[0]\n",
    "df = tables[0]\n",
    "df.columns = [\"Description\", \"Value\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_info_table = df.to_html(index=False)\n",
    "mars_info_table.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('mars_info_table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to process webpage and retrieve hemisphere images of Mars\n",
    "\n",
    "def get_hemi_img(brwr, hemi_url, hemi_name):\n",
    "    \n",
    "    # since browser will take sometime to load,\n",
    "    # create timer to delay the process and wait for chrome to load page\n",
    "    # set wait time parameters\n",
    "    t_wait = 0\n",
    "    t_out = 10\n",
    "    del_t = 0.25\n",
    "    \n",
    "    # access & get content by soup object\n",
    "    browser.visit(hemi_url)\n",
    "    soup = bsp(browser.html, lib_used)\n",
    "    \n",
    "    print(\">> Progress = 10%\")\n",
    "    \n",
    "    # condition to make sure the webpage is loaded\n",
    "    if browser.is_element_present_by_tag('/html') == False:\n",
    "        time.sleep(t_wait)\n",
    "        t_wait += del_t\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\">> Progress = 30%\")\n",
    "    \n",
    "    # click on couple of buttons to gain access to the full size image page\n",
    "    # condition with if to make sure the subsequent codes will still run incase of issue\n",
    "    if brwr.links.find_by_partial_text(hemi_name):\n",
    "        brwr.links.find_by_partial_text(hemi_name).click()\n",
    "        # condition to make sure the webpage is loaded\n",
    "        print(\">> Progress = 50%\")\n",
    "        if brwr.is_element_present_by_tag('/html') == False:\n",
    "            if t_wait <= t_out:\n",
    "                time.sleep(t_wait)\n",
    "                t_wait += del_t\n",
    "        else:\n",
    "            print(\"Page takes too long to load!\")\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        print(f\"Unable to find {hemi_name} Hemisphere Image\")\n",
    "        pass\n",
    "    \n",
    "    print(\">> Progress = 60%\")\n",
    "    # create soup object\n",
    "    soup = bsp(browser.html, lib_used)\n",
    "    \n",
    "    # return results\n",
    "    results = soup.find_all('ul', class_='')\n",
    "    print(\">> Progress = 70%\")\n",
    "    # loop to find the tag a and href of the full size image\n",
    "    for rsl in results[0].find_all('a'):\n",
    "        if rsl.attrs[\"href\"] and (rsl.text).lower() == \"sample\":\n",
    "            print('Getting Image Link')\n",
    "            img_link = rsl['href']\n",
    "            print('Getting Image Title')\n",
    "            img_title = hemi_name + ' Hemisphere'\n",
    "    print(\">> Progress = 100%\")\n",
    "    return (img_title, img_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to Mars hemisphere pics\n",
    "hemi_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "hemi_name = ['Cerberus', 'Schiaparelli', 'Syrtis Major', 'Valles Marineris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the list of dictionary of all hemisphere image info\n",
    "hemisphere_image_urls = []\n",
    "for name in hemi_name:\n",
    "    print(f'>> Processing data of {name} Hemisphere')\n",
    "    print(f'>> Please wait ...')\n",
    "    answer = get_hemi_img(browser, hemi_url, name)\n",
    "    dict_each_hemi = {\"title\": answer[0] , \"img_url\": answer[1]}\n",
    "    hemisphere_image_urls.append(dict_each_hemi)\n",
    "    print(f'>> Finish with {name} Hemisphere\\n{(\"-\")*25}')\n",
    "hemisphere_image_urls               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # link to Mars hemisphere pics\n",
    "# hemi_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# # access & get content \n",
    "# browser.visit(hemi_url)\n",
    "\n",
    "# t_wait = 0\n",
    "# del_t = 0.25\n",
    "\n",
    "# # condition to make sure the webpage is loaded\n",
    "# if browser.is_element_present_by_tag('/html') == False:\n",
    "#     time.sleep(t_wait)\n",
    "#     t_wait += del_t\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# # click on couple of buttons to gain access to the full size image page\n",
    "# # condition with if to make sure the subsequent codes will still run incase of issue\n",
    "# if browser.links.find_by_partial_text('Valles Marineris'):\n",
    "#     browser.links.find_by_partial_text('Valles Marineris').click()\n",
    "#     # condition to make sure the webpage is loaded\n",
    "#     if browser.is_element_present_by_tag('/html') == False:\n",
    "#         time.sleep(t_wait)\n",
    "#         t_wait += del_t\n",
    "#     else:\n",
    "#         print(\"Page takes too long to load!\")\n",
    "#         pass\n",
    "# else:\n",
    "#     print(\"Unable to find Valles Marineris Hemisphere Image\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup object\n",
    "soup = bsp(browser.html, lib_used)\n",
    "\n",
    "# return results\n",
    "results = soup.find_all('ul', class_='')\n",
    "\n",
    "# function to loop and get hemi image info\n",
    "def hemi_img_loop(rsl):\n",
    "# loop to find the tag a and href of the full size image\n",
    "    for rsl in results[0].find_all('a'):\n",
    "        if rsl.attrs[\"href\"] and (rsl.text).lower() == \"sample\":\n",
    "            img_link = rsl['href']\n",
    "            img_title = rsl.text\n",
    "    return (img_title, img_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_img_loop(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valles_img_link = results.a['href']\n",
    "valles_img_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Cerberus Hemisphere Enhanced thumbnail\n",
    "Cerberus Hemisphere Enhanced\n",
    "image/tiff 21 MB\n",
    "Mosaic of the Cerberus hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of 104 Viking Orbiter images acquired…\n",
    "\n",
    "Schiaparelli Hemisphere Enhanced thumbnail\n",
    "Schiaparelli Hemisphere Enhanced\n",
    "image/tiff 35 MB\n",
    "Mosaic of the Schiaparelli hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The images were acquired in 1980 during early northern…\n",
    "\n",
    "Syrtis Major Hemisphere Enhanced thumbnail\n",
    "Syrtis Major Hemisphere Enhanced\n",
    "image/tiff 25 MB\n",
    "Mosaic of the Syrtis Major hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of about 100 red and violet…\n",
    "\n",
    "Valles Marineris Hemisphere Enhanced thumbnail\n",
    "Valles Marineris Hemisphere Enhanced\n",
    "image/tiff 27 MB\n",
    "Mosaic of the Valles Marineris hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The distance is 2500 kilometers from the surface of…\n",
    "\n",
    "\n",
    "# # condition to make sure the webpage is loaded\n",
    "# if browser.is_element_present_by_tag('/html') == False:\n",
    "#     time.sleep(t_wait)\n",
    "#     t_wait += del_t\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python37664bitpythondataconda7a66ec31ac78449888e028f7d32996f5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
